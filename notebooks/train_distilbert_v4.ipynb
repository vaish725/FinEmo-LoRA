{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db432dc",
   "metadata": {},
   "source": [
    "# DistilBERT v4 - Single-Stage Training\n",
    "\n",
    "**Reality Check:** v2's 61% came from 2-stage training (GoEmotions pre-training + FinGPT)\n",
    "\n",
    "**This is single-stage training** - DistilBERT directly on financial data\n",
    "\n",
    "**Dataset:** fingpt_annotated_balanced.csv\n",
    "- 928 samples\n",
    "- 0 duplicates\n",
    "- Balanced minority classes\n",
    "\n",
    "**Config:**\n",
    "- 30 epochs with early stopping\n",
    "- r=16 LoRA rank  \n",
    "- lr=5e-5\n",
    "- Warmup + weight decay\n",
    "\n",
    "**Realistic target:** 50-55% (single-stage baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install -q transformers peft datasets accelerate evaluate scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d130b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Use the clean balanced dataset (928 samples, no duplicates)\n",
    "DATA_PATH = '/content/drive/MyDrive/FinEmo-LoRA/data/annotated/fingpt_annotated_balanced.csv'\n",
    "MODEL_SAVE_PATH = '/content/drive/MyDrive/FinEmo-LoRA/models/distilbert-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88047f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import evaluate\n",
    "\n",
    "EMOTIONS = ['anxiety', 'excitement', 'fear', 'hope', 'optimism', 'uncertainty']\n",
    "emotion2id = {e: i for i, e in enumerate(EMOTIONS)}\n",
    "id2emotion = {i: e for e, i in emotion2id.items()}\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['label'] = df['emotion'].map(emotion2id)\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Class distribution:\\n{df['emotion'].value_counts()}\\n\")\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df['label'])\n",
    "\n",
    "class_counts = temp_df['label'].value_counts()\n",
    "problematic = class_counts[class_counts == 1].index.tolist()\n",
    "\n",
    "if problematic:\n",
    "    prob_df = temp_df[temp_df['label'].isin(problematic)]\n",
    "    temp_df = temp_df[~temp_df['label'].isin(problematic)]\n",
    "else:\n",
    "    prob_df = pd.DataFrame()\n",
    "\n",
    "if not temp_df.empty:\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df['label'])\n",
    "else:\n",
    "    val_df = pd.DataFrame(columns=df.columns)\n",
    "    test_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "if not prob_df.empty:\n",
    "    val_df = pd.concat([val_df, prob_df], ignore_index=True)\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DistilBERT with improved LoRA config\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6,\n",
    "    id2label=id2emotion,\n",
    "    label2id=emotion2id\n",
    ")\n",
    "\n",
    "# Improved LoRA: r=16, target all attention\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"k_lin\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label']]).map(tokenize, batched=True, remove_columns=['text'])\n",
    "val_dataset = Dataset.from_pandas(val_df[['text', 'label']]).map(tokenize, batched=True, remove_columns=['text'])\n",
    "test_dataset = Dataset.from_pandas(test_df[['text', 'label']]).map(tokenize, batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = evaluate.load(\"accuracy\").compute(predictions=predictions, references=labels)\n",
    "    f1 = evaluate.load(\"f1\").compute(predictions=predictions, references=labels, average='macro')\n",
    "    return {'accuracy': acc['accuracy'], 'f1': f1['f1']}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_SAVE_PATH,\n",
    "    num_train_epochs=30,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=2,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=10,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_total_limit=3,\n",
    "    seed=SEED,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining Config:\")\n",
    "print(f\"- Model: DistilBERT single-stage\")\n",
    "print(f\"- Epochs: 30 (early stop after 5 epochs no improvement)\")\n",
    "print(f\"- LoRA rank: r=16, alpha=32\")\n",
    "print(f\"- Learning rate: 5e-5\")\n",
    "print(f\"- Batch size: 16 x 2 accumulation = 32 effective\")\n",
    "print(f\"- Train samples: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd63116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "results = trainer.evaluate(test_dataset)\n",
    "print(f\"\\nTest Accuracy: {results['eval_accuracy']:.4f}\")\n",
    "print(f\"Test F1: {results['eval_f1']:.4f}\")\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = test_df['label'].values\n",
    "\n",
    "present_labels = np.unique(y_true)\n",
    "filtered_names = [id2emotion[label] for label in present_labels]\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, labels=present_labels, target_names=filtered_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ec2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=EMOTIONS, yticklabels=EMOTIONS)\n",
    "plt.title('DistilBERT v4 Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0185cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all versions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON: v2 vs v3 (FinBERT) vs v4 (DistilBERT)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Version': ['v2', 'v3', 'v4'],\n",
    "    'Base Model': ['DistilBERT', 'FinBERT', 'DistilBERT'],\n",
    "    'Data Size': ['200', '1000', '1000'],\n",
    "    'LoRA Rank': ['r=8', 'r=8', 'r=16'],\n",
    "    'Epochs': ['10', '10', '20'],\n",
    "    'LR': ['2e-4', '1e-4', '5e-5'],\n",
    "    'Accuracy': ['61.0%', '42.9%', f\"{results['eval_accuracy']:.1%}\"],\n",
    "    'F1': ['0.610', '0.246', f\"{results['eval_f1']:.3f}\"]\n",
    "})\n",
    "\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "if results['eval_accuracy'] > 0.68:\n",
    "    print(f\"\\nSUCCESS: v4 beats v2 by {(results['eval_accuracy'] - 0.61)*100:.1f}pp\")\n",
    "    print(\"DistilBERT with more data and better config wins.\")\n",
    "elif results['eval_accuracy'] > 0.61:\n",
    "    print(f\"\\nIMPROVED: v4 beats v2 by {(results['eval_accuracy'] - 0.61)*100:.1f}pp\")\n",
    "    print(\"5x more data made the difference.\")\n",
    "else:\n",
    "    print(f\"\\nNo improvement over v2. Accuracy: {results['eval_accuracy']:.1%}\")\n",
    "    print(\"Next steps: Check data quality or try RoBERTa-base\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
